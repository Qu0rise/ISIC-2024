{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"DCGAN","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Advanced data augmentation for image - part 1\n* reference:  https://github.com/rossettisimone/AUGMENTATION_GAN\n* dose it improve your model? pleas let us know in the comment \n* Are you intrested in knowing more?? https://www.nature.com/articles/s41598-019-52737-x\n* please check the discussion page for more information\n* Would you like to see more ? pleas like the page \n\n*** why fake data is not so good? it is trained on a very small dataset for sake of GPU! go bigger ***","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function\n#%matplotlib inline\nimport argparse\nimport datetime\nimport os\nimport os.path\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nfrom torchvision.utils import save_image\nfrom torch.utils.data import SubsetRandomSampler\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\nfrom IPython.display import clear_output\nfrom tqdm import tqdm","metadata":{"id":"gLM6o1DSjcXJ","execution":{"iopub.status.busy":"2024-08-04T13:19:20.68408Z","iopub.execute_input":"2024-08-04T13:19:20.68502Z","iopub.status.idle":"2024-08-04T13:19:26.138958Z","shell.execute_reply.started":"2024-08-04T13:19:20.684983Z","shell.execute_reply":"2024-08-04T13:19:26.137967Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n%cd /kaggle/input/isic-2024-challenge/train-image/image","metadata":{"id":"hZ7QF4YbN1Pl","outputId":"fb1c388d-348b-433a-dbe1-8b0a31acb23a","execution":{"iopub.status.busy":"2024-08-04T13:19:26.140606Z","iopub.execute_input":"2024-08-04T13:19:26.141004Z","iopub.status.idle":"2024-08-04T13:19:26.147889Z","shell.execute_reply.started":"2024-08-04T13:19:26.140978Z","shell.execute_reply":"2024-08-04T13:19:26.146945Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nbatch_size = 32\n# Number of training epochs\nnum_epochs = 200\nLOAD_MODEL = True\n\n#PATH='/AUGMENTATION_GAN/gan_models/epoch_200/p_virus_200_2020-08-22_15:49:13.dat' #P_vir_200_opt\n#PATH='/AUGMENTATION_GAN/gan_models/epoch_200/p_bacteria_200_2020-08-22_16:21:47.dat' #P_bac_200_opt\n#PATH='/AUGMENTATION_GAN/gan_models/epoch_200/normal_200_2020-08-22_16:38:52.dat' #Normal_200_opt\n#PATH='/AUGMENTATION_GAN/gan_models/epoch_200/covid_200_2020-08-22_16:58:21.dat' #Covid_200_opt\n\nTRAIN_ALL = False\n#All images will be resized to this size using a transformer.\nimage_size = 64\n\n# Number of channels in the training images. For color images this is 3\nnc = 3\n\n# Size of z latent vector (i.e. size of generator input)\nnz = 100\n\n# Size of feature maps in generator\nngf = 64\n\n# Size of feature maps in discriminator\nndf = 64\n\n# Learning rate for optimizers\nlr = 0.002\nlr_d = 0.0002\n# Beta1 hyperparam for Adam optimizers\nbeta1 = 0.5\n# Beta2 hyperparam for Adam optimizers\nbeta2 = 0.999\n\nreal_label = 1.\nfake_label = 0.\n# Input to generator\nfixed_noise = torch.randn(64, nz, 1, 1, device=device) #batch of 64\n# Define Loss function\ncriterion = nn.BCELoss()","metadata":{"id":"5MdEuFt0nkmc","execution":{"iopub.status.busy":"2024-08-04T13:19:26.152908Z","iopub.execute_input":"2024-08-04T13:19:26.153208Z","iopub.status.idle":"2024-08-04T13:19:27.780168Z","shell.execute_reply.started":"2024-08-04T13:19:26.153184Z","shell.execute_reply":"2024-08-04T13:19:27.779138Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)","metadata":{"id":"HHXGFAtBHH4R","execution":{"iopub.status.busy":"2024-08-04T13:19:27.781536Z","iopub.execute_input":"2024-08-04T13:19:27.781914Z","iopub.status.idle":"2024-08-04T13:19:27.788385Z","shell.execute_reply.started":"2024-08-04T13:19:27.781877Z","shell.execute_reply":"2024-08-04T13:19:27.78743Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class Generator(nn.Module):\n\n#     def __init__(self):\n#         super(Generator, self).__init__()\n#         self._model = nn.Sequential(\n#             # input is Z, going into a convolution\n#             #i/p,o/p,kernel size,stride,padding\n#             nn.ConvTranspose2d( nz, ngf * 16, 4, 1, 0, bias=False),\n#             nn.BatchNorm2d(ngf * 16),\n#             nn.ReLU(True),\n#             # state size. (ngf*16) x 4 x 4\n#             nn.ConvTranspose2d( ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n#             nn.BatchNorm2d(ngf * 8),\n#             nn.ReLU(True),\n#             # state size. (ngf*8) x 8 x 8\n#             nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n#             nn.BatchNorm2d(ngf * 4),\n#             nn.ReLU(True),\n#             # state size. (ngf*4) x 16 x 16\n#             nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n#             nn.BatchNorm2d(ngf * 2),\n#             nn.ReLU(True),\n#             # state size. (ngf*2) x 32 x 32\n#             nn.ConvTranspose2d( ngf*2, nc, 4, 2, 1, bias=False),\n#             nn.Tanh()\n#             # state size. (nc) x 64 x 64\n#         )\n\n#     def forward(self, input):\n#         return self._model(input)\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.main = nn.Sequential(\n            # input is Z, going into a convolution\n            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            # state size. (ngf*8) x 4 x 4\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            # state size. (ngf*4) x 8 x 8\n            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # state size. (ngf) x 32 x 32\n            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n            # state size. (nc) x 64 x 64\n        )\n\n    def forward(self, input):\n        return self.main(input)","metadata":{"id":"F4uvXCj5zzNa","execution":{"iopub.status.busy":"2024-08-04T13:19:27.789655Z","iopub.execute_input":"2024-08-04T13:19:27.789915Z","iopub.status.idle":"2024-08-04T13:19:27.804048Z","shell.execute_reply.started":"2024-08-04T13:19:27.789892Z","shell.execute_reply":"2024-08-04T13:19:27.803158Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class Discriminator(nn.Module):\n\n#     def __init__(self):\n#         super(Discriminator, self).__init__()\n#         self._model = nn.Sequential(\n#             # input is (nc) x 64 x 64\n#             nn.Conv2d(nc, ndf * 2, 4, 2, 1, bias=False),\n#             nn.LeakyReLU(0.2, inplace=True),\n#             # state size. (ndf*2) x 32 x 32\n#             nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n#             nn.BatchNorm2d(ndf * 4),\n#             nn.LeakyReLU(0.2, inplace=True),\n#             # state size. (ndf*4) x 16 x 16\n#             nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n#             nn.BatchNorm2d(ndf * 8),\n#             nn.LeakyReLU(0.2, inplace=True),\n#             # state size. (ndf*8) x 8 x 8\n#             nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False),\n#             nn.BatchNorm2d(ndf * 16),\n#             nn.LeakyReLU(0.2, inplace=True),\n#             # state size. (ndf*16) x 4 x 4\n#             nn.Conv2d(ndf * 16, 1, 4, 1, 0, bias=False),\n#             nn.Sigmoid()\n#         )\n\n#     def forward(self, input):\n#         return self._model(input)\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.main = nn.Sequential(\n            # input is (nc) x 64 x 64\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(p=0.5),\n            # state size. (ndf) x 32 x 32\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*2) x 16 x 16\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(p=0.5),\n            # state size. (ndf*4) x 8 x 8\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.Dropout(p=0.25),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*8) x 4 x 4\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.main(input)","metadata":{"id":"CEb5BlY5GO4_","execution":{"iopub.status.busy":"2024-08-04T13:19:27.805441Z","iopub.execute_input":"2024-08-04T13:19:27.806083Z","iopub.status.idle":"2024-08-04T13:19:27.81917Z","shell.execute_reply.started":"2024-08-04T13:19:27.806048Z","shell.execute_reply":"2024-08-04T13:19:27.818331Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot(name, train_epoch, values, path, save):\n    clear_output(wait=True)\n    plt.close('all')\n    fig = plt.figure()\n    fig = plt.ion()\n    fig = plt.subplot(1, 1, 1)\n    fig = plt.title('epoch: %s -> %s: %s' % (train_epoch, name, values[-1]))\n    fig = plt.ylabel(name)\n    fig = plt.xlabel('train_set')\n    fig = plt.plot(values)\n    fig = plt.grid()\n    get_fig = plt.gcf()\n    fig = plt.draw()  # draw the plot\n    fig = plt.pause(1)  # show it for 1 second\n    if save:\n        now = datetime.datetime.now()\n        get_fig.savefig('%s/%s_%.3f_%d_%s.png' %\n                        (path, name, train_epoch, values[-1], now.strftime(\"%Y-%m-%d_%H:%M:%S\")))","metadata":{"id":"YVLWLMetCrGe","execution":{"iopub.status.busy":"2024-08-04T13:19:27.820189Z","iopub.execute_input":"2024-08-04T13:19:27.820506Z","iopub.status.idle":"2024-08-04T13:19:27.832482Z","shell.execute_reply.started":"2024-08-04T13:19:27.820483Z","shell.execute_reply":"2024-08-04T13:19:27.83169Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\ndef save_model(generator, discriminator, gen_optimizer, dis_optimizer, metrics, num_epochs):\n    now = datetime.datetime.now()\n    g_losses = metrics['train.G_losses'][-1]\n    d_losses = metrics['train.D_losses'][-1]\n    name = \"%+.3f_%+.3f_%d_%s.dat\" % (g_losses, d_losses, num_epochs, now.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n    fname = os.path.join('.', '/kaggle/working/augGAN/model', name)\n    states = {\n            'state_dict_generator': generator.state_dict(),\n            'state_dict_discriminator': discriminator.state_dict(),\n            'gen_optimizer': gen_optimizer.state_dict(),\n            'dis_optimizer': dis_optimizer.state_dict(),\n            'metrics': metrics,\n            'train_epoch': num_epochs,\n            'date': now.strftime(\"%Y-%m-%d_%H:%M:%S\"),\n    }\n    torch.save(states, fname)\n    path='/kaggle/working/augGAN/plots/train_%+.3f_%+.3f_%s'% (g_losses, d_losses, now.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n    try:\n        os.makedirs(path, exist_ok=True)\n    except Exception as error:\n        print(error)\n    try:\n        os.mkdir(os.path.join('.', path))\n    except Exception as error:\n        print(error)\n\n    plot('G_losses', num_epochs, metrics['train.G_losses'], path, True)\n    plot('D_losses', num_epochs, metrics['train.D_losses'], path, True)\n    plot('D_x', num_epochs, metrics['train.D_x'], path, True)\n    plot('D_G_z1', num_epochs, metrics['train.D_G_z1'], path, True)\n    plot('D_G_z2', num_epochs, metrics['train.D_G_z2'], path, True)","metadata":{"id":"zHGbk-t3imrL","execution":{"iopub.status.busy":"2024-08-04T13:19:27.83359Z","iopub.execute_input":"2024-08-04T13:19:27.833884Z","iopub.status.idle":"2024-08-04T13:19:27.867894Z","shell.execute_reply.started":"2024-08-04T13:19:27.833861Z","shell.execute_reply":"2024-08-04T13:19:27.866953Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_list = []\nG_losses = []\nD_losses = []\n\ndef train_gan(generator, discriminator, gen_optimizer, dis_optimizer, train_loader, num_epochs, metrics):\n        iters = 0\n        print(\"GAN training started :D...\")\n\n        for epoch in range(num_epochs):\n            print(\"Epoch %d\" %(epoch+1))\n            # For each batch in the dataloader\n            for i, data in enumerate(tqdm(train_loader, 0)):\n                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n                ## Train with all-real batch\n                discriminator.zero_grad()\n                # Format batch\n                b_real = data[0].to(device)\n                b_size = b_real.size(0)\n                label = torch.full((b_size,), real_label, device=device)\n                # Forward pass real batch through D\n                output = discriminator(b_real).view(-1)\n                # Calculate loss on all-real batch\n                errD_real = criterion(output, label)\n                # Calculate gradients for D in backward pass\n                errD_real.backward()\n                D_x = output.mean().item()\n                metrics['train.D_x'].append(D_x)\n\n                ## Train with all-fake batch\n                # Generate batch of latent vectors\n                noise = torch.randn(b_size, nz, 1, 1, device=device)\n                # Generate fake image batch with G\n                fake = generator(noise)\n                label.fill_(fake_label)\n                # Classify all fake batch with D\n                output = discriminator(fake.detach()).view(-1)\n                # Calculate D's loss on the all-fake batch\n                errD_fake = criterion(output, label)\n                # Calculate the gradients for this batch\n                errD_fake.backward()\n                D_G_z1 = output.mean().item()\n                metrics['train.D_G_z1'].append(D_G_z1)\n                # Add the gradients from the all-real and all-fake batches\n                errD = errD_real + errD_fake\n                # Update D\n                dis_optimizer.step()\n                # if i>0:\n                #     if errD.item()>G_losses[i-1]:\n                #         dis_optimizer.step()\n                # else:\n                #     dis_optimizer.step()\n\n                # (2) Update G network: maximize log(D(G(z)))\n                generator.zero_grad()\n                label.fill_(real_label)  # fake labels are real for generator cost\n                # Since we just updated D, perform another forward pass of all-fake batch through D\n                output = discriminator(fake).view(-1)\n                # Calculate G's loss based on this output\n                errG = criterion(output, label)\n                # Calculate gradients for G\n                errG.backward()\n                D_G_z2 = output.mean().item()\n                metrics['train.D_G_z2'].append(D_G_z2)\n                # Update G\n                gen_optimizer.step()\n\n                # Save Losses for plotting later\n                G_losses.append(errG.item())\n                D_losses.append(errD.item())\n                metrics['train.G_losses'].append(errG.item())\n                metrics['train.D_losses'].append(errD.item())\n\n                # Check how the generator is doing by saving G's output on fixed_noise\n                if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_loader)-1)):\n                    with torch.no_grad():\n                        fake = generator(fixed_noise).detach().cpu()\n                    img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n\n                iters += 1\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n                  % (epoch+1, num_epochs, i, len(train_loader),\n                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n        save_model(generator, discriminator, gen_optimizer, dis_optimizer, metrics, num_epochs)","metadata":{"id":"xn5d4tccMIyL","execution":{"iopub.status.busy":"2024-08-04T13:19:27.872163Z","iopub.execute_input":"2024-08-04T13:19:27.872513Z","iopub.status.idle":"2024-08-04T13:19:27.888859Z","shell.execute_reply.started":"2024-08-04T13:19:27.872478Z","shell.execute_reply":"2024-08-04T13:19:27.887877Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_indices(dataset, class_name, indices):\n    j = 0\n    for i in range(len(dataset.targets)):\n        if dataset.targets[i] == class_name:\n            indices.append(i)\n            j += 1\n    print(\"Total Samples of class\", class_name,\"found are\",j)\n    return indices","metadata":{"id":"gPHMkQQKJItb","execution":{"iopub.status.busy":"2024-08-04T13:19:27.890185Z","iopub.execute_input":"2024-08-04T13:19:27.890537Z","iopub.status.idle":"2024-08-04T13:19:27.901747Z","shell.execute_reply.started":"2024-08-04T13:19:27.890506Z","shell.execute_reply":"2024-08-04T13:19:27.90093Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test1(generator, discriminator, num_epochs, metrics):\n    print('Testing Block.........')\n    now = datetime.datetime.now()\n    g_losses = metrics['train.G_losses'][-1]\n    d_losses = metrics['train.D_losses'][-1]\n    path='/kaggle/working/augGAN/output_images'\n    try:\n      os.mkdir(os.path.join('.', path))\n    except Exception as error:\n      print(error)\n\n    test_img_list = []\n    test_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n    test_fake = generator(test_noise).detach().cpu()\n    test_img_list.append(vutils.make_grid(test_fake, padding=2, normalize=True))\n    fig = plt.figure(figsize=(15,15))\n    fig = plt.axis(\"off\")\n    fig = plt.title(\"Fake Images\")\n    fig = plt.imshow(np.transpose(test_img_list[-1],(1,2,0)))\n    get_fig = plt.gcf()\n    fig = plt.show()\n    get_fig.savefig('%s/image_%.3f_%.3f_%d_%s.png' %\n                    (path, g_losses, d_losses, num_epochs, now.strftime(\"%Y-%m-%d_%H:%M:%S\")))","metadata":{"id":"ekCtxRmkLl5R","execution":{"iopub.status.busy":"2024-08-04T13:19:27.90281Z","iopub.execute_input":"2024-08-04T13:19:27.903083Z","iopub.status.idle":"2024-08-04T13:19:27.915484Z","shell.execute_reply.started":"2024-08-04T13:19:27.903057Z","shell.execute_reply":"2024-08-04T13:19:27.914728Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test2(generator, discriminator, num_epochs, metrics, loader):\n    print('Testing Block.........')\n    now = datetime.datetime.now()\n    g_losses = metrics['train.G_losses'][-1]\n    d_losses = metrics['train.D_losses'][-1]\n    path='/kaggle/working/augGAN/output_images'\n    try:\n      os.mkdir(os.path.join('.', path))\n    except Exception as error:\n      print(error)\n\n    real_batch = next(iter(loader))\n    \n    test_img_list = []\n    test_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n    test_fake = generator(test_noise).detach().cpu()\n    test_img_list.append(vutils.make_grid(test_fake, padding=2, normalize=True))\n\n    fig = plt.figure(figsize=(15,15))\n    ax1 = plt.subplot(1,2,1)\n    ax1 = plt.axis(\"off\")\n    ax1 = plt.title(\"Real Images\")\n\n    ax2 = plt.subplot(1,2,2)\n    ax2 = plt.axis(\"off\")\n    ax2 = plt.title(\"Fake Images\")\n    ax2 = plt.imshow(np.transpose(test_img_list[-1],(1,2,0)))\n    #ax2 = plt.show()\n    fig.savefig('%s/image_%.3f_%.3f_%d_%s.png' %\n                    (path, g_losses, d_losses, num_epochs, now.strftime(\"%Y-%m-%d_%H:%M:%S\")))","metadata":{"id":"sjQZEYmqSRyn","execution":{"iopub.status.busy":"2024-08-04T13:19:27.916735Z","iopub.execute_input":"2024-08-04T13:19:27.917119Z","iopub.status.idle":"2024-08-04T13:19:27.927821Z","shell.execute_reply.started":"2024-08-04T13:19:27.917072Z","shell.execute_reply":"2024-08-04T13:19:27.926717Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef test_fake(generator, discriminator, metrics, n_images, folname):\n    now = datetime.datetime.now()\n    g_losses = metrics['train.G_losses'][-1]\n    d_losses = metrics['train.D_losses'][-1]\n    #path='augGAN/output_images/%+.3f_%+.3f_%d_%s'% (g_losses, d_losses, n_images, now.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n    path='main_folder/'+str(n_images)+'/'+folname\n    try:\n      os.mkdir(os.path.join('.', path))\n    except Exception as error:\n      print(error)\n\n    im_batch_size = 50\n    #n_images=100\n    for i_batch in range(0, n_images, im_batch_size):\n        gen_z = torch.randn(im_batch_size, 100, 1, 1, device=device)\n        gen_images = generator(gen_z)\n        dis_result = discriminator(gen_images).view(-1)\n        images = gen_images.to(\"cpu\").clone().detach()\n        images = images.numpy().transpose(0, 2, 3, 1)\n        for i_image in range(gen_images.size(0)):\n            save_image(gen_images[i_image, :, :, :], os.path.join(path, \n                        f'image_{i_batch+i_image:04d}.png'), normalize= True)\n\n    print('Testing Block.........')\n    print('Discriminator_mean: ', dis_result.mean().item())\n    #import shutil\n    #shutil.make_archive('images', 'zip', './augGAN/output_images')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:19:27.92897Z","iopub.execute_input":"2024-08-04T13:19:27.929314Z","iopub.status.idle":"2024-08-04T13:19:27.940993Z","shell.execute_reply.started":"2024-08-04T13:19:27.929282Z","shell.execute_reply":"2024-08-04T13:19:27.940047Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\nimport os\nfrom torch.utils.data import DataLoader, Dataset, Subset\n\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.image_files = [f for f in os.listdir(data_dir) if f.endswith('.jpg') or f.endswith('.png')]\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.data_dir, self.image_files[idx])\n        image = Image.open(img_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, 0  # Return 0 as a dummy label if you don't have labels\ndata_dir = '/kaggle/input/isic-2024-challenge/train-image/image'\n\nmu = (0.5,0.5,0.5)\nsigma = (0.5,0.5,0.5)\ntransform = transforms.Compose([#transforms.RandomHorizontalFlip(),\n                                    transforms.Resize((64,64)),\n                                    #transforms.Scale(imageSize),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize(mu, sigma)])\n# Use the custom dataset\n\n\ntrainset = CustomImageDataset(data_dir, transform=transform)\n\nsubset_size = 300    #of samples in the subset\nsubset_indices = random.sample(range(len(trainset)), subset_size)\nsubset_dataset = Subset(trainset, subset_indices)\n\ntrainset = subset_dataset","metadata":{"id":"LWeXmdInu38z","outputId":"67931a1e-780f-427d-b963-43b0b461417c","execution":{"iopub.status.busy":"2024-08-04T13:19:27.942022Z","iopub.execute_input":"2024-08-04T13:19:27.942319Z","iopub.status.idle":"2024-08-04T13:19:28.343954Z","shell.execute_reply.started":"2024-08-04T13:19:27.942285Z","shell.execute_reply":"2024-08-04T13:19:28.343162Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generator = Generator().to(device)\ndiscriminator = Discriminator().to(device)\ngenerator.apply(weights_init)\ndiscriminator.apply(weights_init)\ngen_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\ndis_optimizer = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(beta1, beta2))\n\n\nMETRIC_FIELDS = [\n    'train.D_x',\n    'train.D_G_z1',\n    'train.D_G_z2',\n    'train.G_losses',\n    'train.D_losses',\n]\nmetrics = {field: list() for field in METRIC_FIELDS}\n\n\nTRAIN_ALL = False\n\nif TRAIN_ALL:\n    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                                  shuffle=True)\n    train_gan(generator, discriminator, gen_optimizer, dis_optimizer, train_loader,\n              num_epochs, metrics)\n    test2(generator, discriminator, num_epochs, metrics, train_loader)\nelse:\n    # idx = []\n    # idx = get_indices(train_set, 4, idx) #second argument is 0 for covid; 1 for normal; 2 for pneumonia_bacteria; 3 for pneumonia_virus for x-ray dataset\n \n    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                                  shuffle=True)\n    mask =[x[1]==0 for x in train_loader.dataset] #here is 0 for covid; 1 for normal; 2 for pneumonia_bacteria; 3 for pneumonia_virus for x-ray dataset\n    idx= np.arange(len(train_loader.dataset))[mask]\n\n    print(\"Total samples now are \",len(idx))\n    selected_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                                      sampler = SubsetRandomSampler(idx))\n    try:\n        train_gan(generator, discriminator, gen_optimizer, dis_optimizer, selected_loader,num_epochs, metrics)\n    except:\n        model_dir = '/kaggle/working/augGAN'\n        os.makedirs(model_dir, exist_ok=True)\n        model_dir = '/kaggle/working/augGAN/model'\n        os.makedirs(model_dir, exist_ok=True)\n        train_gan(generator, discriminator, gen_optimizer, dis_optimizer, selected_loader,num_epochs, metrics)\n    test2(generator, discriminator, num_epochs, metrics, selected_loader)\n    test1(generator, discriminator, num_epochs, metrics)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:19:28.345162Z","iopub.execute_input":"2024-08-04T13:19:28.345465Z","iopub.status.idle":"2024-08-04T13:24:48.022471Z","shell.execute_reply.started":"2024-08-04T13:19:28.34544Z","shell.execute_reply":"2024-08-04T13:24:48.021572Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Testing cell....to visualize \ntest_batch = 1 #No of images to be genertaed in stack \ntest_fake_id = 1 #To generate fake images or just view real images\nLOAD_ID = 0 #Class of images in case test_fake_id is 0\ngenerator = Generator().to(device)\ndiscriminator = Discriminator().to(device)\n\nif test_fake_id:\n  #check for fake image\n  test_img_list = []\n  test_noise = torch.randn(test_batch, nz, 1, 1, device=device)\n  test_img = generator(test_noise)#.detach().cpu()\n\nelse:\n  #check for real image\n  idx = []\n  #train_set = datasets.ImageFolder(\"main_folder/100/\", transform=transform)\n  idx = get_indices(train_set, LOAD_ID, idx) \n  test_loader = torch.utils.data.DataLoader(train_set, batch_size=test_batch,\n                                                sampler = SubsetRandomSampler(idx))\n  data = next(iter(test_loader))\n  test_noise, test_class_lable = data\n  test_img.data.resize_(test_noise.size()).copy_(test_noise)\n  #print(data[0].size())\n  print('class label for real', test_class_lable)\n\ns_output = discriminator(test_img.detach().to(device))\nprint('Discriminator s o/p', s_output)\n\n","metadata":{"id":"A1Zz7NErSjEG","outputId":"5044b9ed-2c23-4fd8-9fa1-6f495beb3f17","execution":{"iopub.status.busy":"2024-08-04T13:24:48.023578Z","iopub.execute_input":"2024-08-04T13:24:48.023838Z","iopub.status.idle":"2024-08-04T13:24:48.351123Z","shell.execute_reply.started":"2024-08-04T13:24:48.023814Z","shell.execute_reply":"2024-08-04T13:24:48.350079Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-08-04T13:24:48.352431Z","iopub.execute_input":"2024-08-04T13:24:48.352809Z","iopub.status.idle":"2024-08-04T13:25:02.023525Z","shell.execute_reply.started":"2024-08-04T13:24:48.352774Z","shell.execute_reply":"2024-08-04T13:25:02.022492Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchsummary import summary\n\nsummary(generator, (100, 1, 1))\nsummary(discriminator, (3, 64, 64))","metadata":{"id":"8la1EFeB3zRF","outputId":"c864d9ed-c889-4244-a5c4-db51946ca646","execution":{"iopub.status.busy":"2024-08-04T13:25:02.024906Z","iopub.execute_input":"2024-08-04T13:25:02.025206Z","iopub.status.idle":"2024-08-04T13:25:02.056809Z","shell.execute_reply.started":"2024-08-04T13:25:02.02518Z","shell.execute_reply":"2024-08-04T13:25:02.055862Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(generator)","metadata":{"id":"4N0yiqHfzOzX","outputId":"9599816b-3707-49c0-c869-932427a16458","execution":{"iopub.status.busy":"2024-08-04T13:25:02.058537Z","iopub.execute_input":"2024-08-04T13:25:02.059064Z","iopub.status.idle":"2024-08-04T13:25:02.064574Z","shell.execute_reply.started":"2024-08-04T13:25:02.059027Z","shell.execute_reply":"2024-08-04T13:25:02.063536Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(discriminator)","metadata":{"id":"o-Z61n2SAhlv","outputId":"671b8da4-7a8b-4136-948f-9b057aa52075","execution":{"iopub.status.busy":"2024-08-04T13:25:02.065854Z","iopub.execute_input":"2024-08-04T13:25:02.066261Z","iopub.status.idle":"2024-08-04T13:25:02.075447Z","shell.execute_reply.started":"2024-08-04T13:25:02.066235Z","shell.execute_reply":"2024-08-04T13:25:02.074539Z"},"trusted":true},"outputs":[],"execution_count":null}]}